# Text Analytics

### About the Corpus
The corpus is comprised of articles selcted by the students under the general guideline "about the presidency".  It was started during right after the 2016 Presidential elections when students were asked to select a couple of articles from known news sources about the new president.  Over subsequent classes, the corpus grew, making it a rick souce for text analytics.

The professor's description on material selection was:

"**EVERYONE PAY ATTENTION TO THIS**: I've selected a topic on which you may already have an opinion. **__You may have a strong      opinion. This class is NOT the place to be sharing your opinion - directly or even indirectly__**. You're not trying to make a case,    or prove a point. Your goal is to be as machine-like as possible - just finding representative data, and going through the text          analytics process.

        The Case Study 2 Topic is: "Donald Trump's Presidency"



### Course Description
This course is focused on incorporating text data from a wide range of sources and utilizing those data to guide management decisions. Topics covered include extracting key concepts from text, organizing extracted information into meaningful categories, linking concepts together, and creating structured data elements from extracted concepts. Students identify an area of interest and collect relevant text documents, building a document corpus for in-depth analysis using methods of natural language processing and text analytics. This is a case-study and project-based course with a strong programming component.

### Course Learning Outcomes 
By the end of this course, you will be able to:
+   Identify role of text analytics in the data sciences arena; identify several cases where organizations have found value, identify trends in organizational use of text analytics,
+   Identify and characterize potential data sources; identify quality and ranking criteria, 
+   Identify how different kinds of data may require different text analytic approaches; identify data scrubbing requirements, 
+   Understand how to characterize and metatag content, 
+   Extract both entities and concepts; be able to identify, characterize, and use methods for entity and concept co-resolution; identify and characterize strategies for complex concept extraction, understand the challenges with named entity co-resolution, 
+   Understand how clustering and classification algorithms, together with other forms of machine learning (both supervised and unsupervised) play a role in text analytics,
+   Understand how statistical data processing (leading up to graph representations) maps entities and concepts to each other, and also provides a mapping across source documents, 
+   Understand and be able to apply methods for sentiment analysis and link analysis, 
+   Understand and be able to characterize certain text analytics / natural language processing (NLP) data repositories (combined with algorithms) can be useful, specifically Googleâ€™s Word2Vec and Doc2Vec,
+   Understand and be able to develop (at a basic level) both ontologies and taxonomies that can provide interpretation during text analytics,
+   Understand how generative machine learning methods, such as latent semantic analysis (LSA) and latent Direchlet Allocation (LDA), can be useful in text analytics / NLP, and
+   Be able to understand the full extent and complexity of text analytics in the context of the current Case Study, where text analytics have been applied to generate useful results. 
