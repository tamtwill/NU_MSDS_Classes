for(i in 1:19){
coefi=coef(regfit.fwd, id=i)
pred=test.mat[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[test]-pred)^2)
}
val.errors
plot(sqrt(val.errors), ylab="Root MSE", ylim=c(300,400), pch=19, type='b')
points(sqrt(regfit.fwd$rss[-1]/180), col='blue', pch=19, type='b')
legend('topright', legend = "text")
val.errors=rep(NA,19)
for(i in 1:19){
coefi=coef(regfit.fwd, id=i)
pred=test.mat[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[test]-pred)^2)
}
val.errors
val.errors=rep(NA,19)
for(i in 1:19){
coefi=coef(regfit.best, id=i)
pred=test.mat[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[test]-pred)^2)
}
val.errors
plot(sqrt(val.errors), ylab="Root MSE", ylim=c(300,400), pch=19, type='b')
points(sqrt(regfit.fwd$rss[-1]/180), col='blue', pch=19, type='b')
legend('topright', legend = "text")
plot(sqrt(val.errors), ylab="Root MSE", ylim=c(300,500), pch=19, type='b')
points(sqrt(regfit.fwd$rss[-1]/180), col='blue', pch=19, type='b')
legend('topright', legend = "text")
which.min(val.errors)
coef(regfit.best ,10)
folds=sample(1:k,nrow(Hitters),replace=TRUE)
cv.errors=matrix(NA,k,19, dimnames=list(NULL, paste(1:19)))
k=10
set.seed (11)   #video
folds=sample(1:k,nrow(Hitters),replace=TRUE)
cv.errors=matrix(NA,k,19, dimnames=list(NULL, paste(1:19)))
folds
set.seed (1)   #video
folds=sample(1:k,nrow(Hitters),replace=TRUE)
folds
set.seed (11)
folds=sample(rep(1:10, length=nrow(Hitters)))
folds
k=10
set.seed (1)       #book
folds=sample(1:k,nrow(Hitters),replace=TRUE)
cv.errors=matrix(NA,k,19, dimnames=list(NULL, paste(1:19)))
for(j in 1:k){
best.fit=regsubsets(Salary~.,data=Hitters[folds!=j,], nvmax=19)
for(i in 1:10){
pred=predict(best.fit,Hitters[folds==j,],id=i)
cv.errors[j,i]=mean((Hitters$Salary[folds==j]-pred)^2)
}
}
mean.cv.errors=apply(cv.errors ,2,mean)
mean.cv.errors
for(j in 1:k){
best.fit=regsubsets(Salary~.,data=Hitters[folds!=j,], nvmax=19)
for(i in 1:19){
pred=predict(best.fit,Hitters[folds==j,],id=i)
cv.errors[j,i]=mean((Hitters$Salary[folds==j]-pred)^2)
}
}
mean.cv.errors=apply(cv.errors ,2,mean)
mean.cv.errors
plot(mean.cv.errors, type='b')
reg.best=regsubsets (Salary~.,data=Hitters , nvmax=19)
coef(reg.best ,11)
x=model.matrix(Salary~.,Hitters)[,-1]
y=Hitters$Salary
grid=10^seq(10,-2,length=100)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
dim(coef(ridge.mod))
ridge.mod$lambda [50]
sqrt(sum(coef(ridge.mod)[-1,50]^2))
coef(rige.mod)[,50]
coef(ridge.mod)[,50]
predict(ridge.mod,s=50,type="coefficients")[1:20,]
set.seed (1)
train=sample(1:nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh =1e -12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,])
ridge.mod=glmnet(x[train,], y[train],alpha=0,lambda=grid, thresh =1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,])
mean((ridge.pred-y.test)^2)
mean((mean(y[train])-y.test)^2)
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2)
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T)
mean((ridge.pred-y.test)^2)
lm(y~x, subset=train)
predict(ridge.mod,s=0,exact=T,type="coefficients")[1:20,]
set.seed (1)
cv.out=cv.glmnet(x[train ,],y[train],alpha=0)
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam
round(bestlam,0)
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])
mean((ridge.pred-y.test)^2)
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:20,]
options(digits=3)
predict(out,type="coefficients",s=bestlam)[1:20,]
lasso.mod=glmnet(x[train ,],y[train],alpha=1,lambda=grid)
plot(lasso.mod)
set.seed (1)
cv.out=cv.glmnet(x[train ,],y[train],alpha=1)
plot(cv.out)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam ,newx=x[test,])
mean((lasso.pred-y.test)^2)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:20,]
lasso.coef
lasso.coef[lasso.coef!=0]
set.seed (2)
pcr.fit=pcr(Salary~., data=Hitters ,scale=TRUE, validation ="CV")
summary(pcr.fit)
library(pls)
install.packages("pls")
pcr.fit=pcr(Salary~., data=Hitters ,scale=TRUE, validation ="CV")
pcr.fit=pcr(Salary~., data=Hitters ,scale=TRUE, validation ="CV")
library(pls)
set.seed (2)
pcr.fit=pcr(Salary~., data=Hitters ,scale=TRUE, validation ="CV")
summary(pcr.fit)
summary(pcr.fit)
validationplot(pcr.fit,val.type="MSEP")
set.seed (1)
pcr.fit=pcr(Salary~., data=Hitters,subset=train,scale=TRUE, validation ="CV")
validationplot(pcr.fit,val.type="MSEP")
pcr.pred=predict(pcr.fit,x[test,],ncomp=7)
mean((pcr.pred-y.test)^2)
pcr.fit=pcr(y~x,scale=TRUE,ncomp=7)
summary(pcr.fit)
set.seed (1)
pls.fit=plsr(Salary~., data=Hitters ,subset=train,scale=TRUE, validation ="CV")
summary(pls.fit)
validationplot(pls.fit,val.type="MSEP")
pls.pred=predict(pls.fit,x[test,],ncomp=2)
mean((pls.pred-y.test)^2)
pls.fit=plsr(Salary~., data=Hitters ,scale=TRUE,ncomp=2)
summary(pls.fit)
2*250 - (2*log(.18))
250*log(.18/250)+2*250
(log(.18))
2*3 - 2*log(.18)
6+1.71
6+2*1.71
2*4 - 2*log(.18)
4*log(.18/4)+2*250
log(250)*4 - 2*(log(.18))
install.packages("rattle")
library (rattle)
rattle::
require (Rattle)
rattle()
require(rattle)
require(rattle)
install.packages("RGtk2")
install.packages(c("boot", "Matrix", "mgcv"))
install.packages(c("boot", "Matrix", "mgcv"))
install.packages(c("boot", "Matrix", "mgcv"))
install.packages(c("boot", "Matrix", "mgcv"))
install.packages(c("boot", "Matrix", "mgcv"))
install.packages(c("boot", "Matrix", "mgcv"))
install.packages(c("boot", "Matrix", "mgcv"))
install.packages(c("boot", "Matrix", "mgcv"))
# For the sake of good programming hygiene, start clean
# Clear Workspace
rm(list=ls())
# Clear Console:
cat("\014")
install.packages(c("boot", "Matrix", "mgcv"))
require(rattle.data)
rattle.data()
rattle.data::weather
require(rattle)
install.packages("rattle")
require(rattle)
library(rattle)
install.packages("cairoDevice")
# For the sake of good programming hygiene, start clean
#------------------------------------------------------
# Clear Workspace
rm(list=ls())
# Clear Console:
cat("\014")
# Set working directory
#------------------------------------------
setwd("~/NorthwesternU_MSPA/Classes/Generalized Linear Models - 411/Bonus Assignments/HELOC")
# include required packages
#---------------------------
library(glmnet)
# Read in the data
#------------------------------------------
df <- read.csv("heloc_test.csv",header=T)
############## Part 1: Data Exploration ##################
str(df)
summary(df)
sum(complete.cases(df))
#convert the text cases to numerics
# df$REASON<- as.numeric(factor(df$REASON))
# df$JOB<- as.numeric(factor(df$JOB))
# convert the N/As to be the column means
for(i in 1:ncol(df)){
df[is.na(df[,i]), i] <- mean(df[,i], na.rm = TRUE)
}
df$predict <-  -2.2436 +
-0.0067 * df_clean$YOJ +
0.5607 * df_clean$DEROG +
0.7564 * df_clean$DELINQ +
-0.0057 * df_clean$CLAGE +
0.1537 * df_clean$NINQ +
-0.0125 * df_clean$CLNO +
0.0492 * df_clean$DEBTINC
df$tmp = exp(df$predict)
df$tmp = df$tmp / (1.0+df$tmp)
df$P_TARGET_FLAG = df$tmp
df$P_TARGET_FLAG <- round(df$P_TARGET_FLAG, 2)
#subset of data set for the deliverable "Scored data file"
prediction <- df[c("INDEX","P_TARGET_FLAG")]
#####
#Note, this next function will output an Excel file in your work environment called write.xlsx.
#####
#Write prediction File
write.csv(prediction, "tam_williams_heloc_scoredv2.csv", row.names = FALSE)
# Clear Workspace
rm(list=ls())
# Clear Console:
cat("\014")
# Set working directory
#------------------------------------------
setwd("~/NorthwesternU_MSPA/Classes/Generalized Linear Models - 411/Bonus Assignments/HELOC")
# include required packages
#---------------------------
library(glmnet)
# Read in the data
#------------------------------------------
df <- read.csv("heloc_test.csv",header=T)
############## Part 1: Data Exploration ##################
str(df)
summary(df)
sum(complete.cases(df))
#convert the text cases to numerics
# df$REASON<- as.numeric(factor(df$REASON))
# df$JOB<- as.numeric(factor(df$JOB))
# convert the N/As to be the column means
for(i in 1:ncol(df)){
df[is.na(df[,i]), i] <- mean(df[,i], na.rm = TRUE)
}
df$predict <-  -2.2436 +
-0.0067 * df_clean$YOJ +
0.5607 * df_clean$DEROG +
0.7564 * df_clean$DELINQ +
-0.0057 * df_clean$CLAGE +
0.1537 * df_clean$NINQ +
-0.0125 * df_clean$CLNO +
0.0492 * df_clean$DEBTINC
df_clean <- read.csv("heloc_test.csv",header=T)
############## Part 1: Data Exploration ##################
str(df)
summary(df)
sum(complete.cases(df))
#convert the text cases to numerics
# df$REASON<- as.numeric(factor(df$REASON))
# df$JOB<- as.numeric(factor(df$JOB))
# convert the N/As to be the column means
for(i in 1:ncol(df)){
df[is.na(df[,i]), i] <- mean(df[,i], na.rm = TRUE)
}
df$predict <-  -2.2436 +
-0.0067 * df_clean$YOJ +
0.5607 * df_clean$DEROG +
0.7564 * df_clean$DELINQ +
-0.0057 * df_clean$CLAGE +
0.1537 * df_clean$NINQ +
-0.0125 * df_clean$CLNO +
0.0492 * df_clean$DEBTINC
df$tmp = exp(df$predict)
df$tmp = df$tmp / (1.0+df$tmp)
df$P_TARGET_FLAG = round(df$tmp, 2)
df$predict <-  -2.2436 +
-0.0067 * df_clean$YOJ +
0.5607 * df_clean$DEROG +
0.7564 * df_clean$DELINQ +
-0.0057 * df_clean$CLAGE +
0.1537 * df_clean$NINQ +
-0.0125 * df_clean$CLNO +
0.0492 * df_clean$DEBTINC
# For the sake of good programming hygiene, start clean
#------------------------------------------------------
# Clear Workspace
rm(list=ls())
# Clear Console:
cat("\014")
# Set working directory
#------------------------------------------
setwd("~/NorthwesternU_MSPA/Classes/Generalized Linear Models - 411/Bonus Assignments/HELOC")
# include required packages
#---------------------------
library(glmnet)
# Read in the data
#------------------------------------------
df_clean <- read.csv("heloc_test.csv",header=T)
############## Part 1: Data Exploration ##################
str(df)
summary(df)
sum(complete.cases(df))
#convert the text cases to numerics
# df$REASON<- as.numeric(factor(df$REASON))
# df$JOB<- as.numeric(factor(df$JOB))
# convert the N/As to be the column means
for(i in 1:ncol(df)){
df[is.na(df[,i]), i] <- mean(df[,i], na.rm = TRUE)
}
df$predict <-  -2.2436 +
-0.0067 * df_clean$YOJ +
0.5607 * df_clean$DEROG +
0.7564 * df_clean$DELINQ +
-0.0057 * df_clean$CLAGE +
0.1537 * df_clean$NINQ +
-0.0125 * df_clean$CLNO +
0.0492 * df_clean$DEBTINC
df$tmp = exp(df$predict)
df$tmp = df$tmp / (1.0+df$tmp)
df$P_TARGET_FLAG = round(df$tmp, 2)
df$predict <-  -2.2436 +
-0.0067 * df_clean$YOJ +
0.5607 * df_clean$DEROG +
0.7564 * df_clean$DELINQ +
-0.0057 * df_clean$CLAGE +
0.1537 * df_clean$NINQ +
-0.0125 * df_clean$CLNO +
0.0492 * df_clean$DEBTINC
df_clean[is.na(df_clean)] <- 0
df$predict <-  -2.2436 +
-0.0067 * df_clean$YOJ +
0.5607 * df_clean$DEROG +
0.7564 * df_clean$DELINQ +
-0.0057 * df_clean$CLAGE +
0.1537 * df_clean$NINQ +
-0.0125 * df_clean$CLNO +
0.0492 * df_clean$DEBTINC
df$predict <-  -2.2436 -0.0067 * df_clean$YOJ + 0.5607 * df_clean$DEROG +
0.7564 * df_clean$DELINQ -0.0057 * df_clean$CLAGE + 0.1537 * df_clean$NINQ +
-0.0125 * df_clean$CLNO + 0.0492 * df_clean$DEBTINC
df$P_TARGET_FLAG <-  -2.2436    +
-0.0067  	* df_clean$YOJ+
0.5607 	* df_clean$DEROG+
0.7564 	* df_clean$DELINQ+
-0.0057 * df_clean$CLAGE+
0.1537 * df_clean$NINQ+
-0.0125 	* df_clean$CLNO+
0.0492  	* df_clean$DEBTINC
# For the sake of good programming hygiene, start clean
#------------------------------------------------------
# Clear Workspace
rm(list=ls())
# Clear Console:
cat("\014")
# Set working directory
#------------------------------------------
setwd("~/NorthwesternU_MSPA/Classes/Generalized Linear Models - 411/Bonus Assignments/HELOC")
# include required packages
#---------------------------
library(glmnet)
# Read in the data
#------------------------------------------
df_clean <- read.csv("heloc_test.csv",header=T)
############## Part 1: Data Exploration ##################
str(df)
summary(df)
sum(complete.cases(df))
#convert the text cases to numerics
# df$REASON<- as.numeric(factor(df$REASON))
# df$JOB<- as.numeric(factor(df$JOB))
# Clean any NAs
df_clean[is.na(df_clean)] <- 0
# convert the N/As to be the column means
for(i in 1:ncol(df)){
df[is.na(df[,i]), i] <- mean(df[,i], na.rm = TRUE)
}
df$predict <- -2.2436 -0.0067 * df_clean$YOJ + 0.5607 * df_clean$DEROG +
0.7564 * df_clean$DELINQ -0.0057 * df_clean$CLAGE + 0.1537 * df_clean$NINQ +
-0.0125 * df_clean$CLNO + 0.0492 * df_clean$DEBTINC
######## Predict 411, HELOC Extra Credit
######## Submitted by: Tamara Williams
# For the sake of good programming hygiene, start clean
#------------------------------------------------------
# Clear Workspace
rm(list=ls())
# Clear Console:
cat("\014")
# Set working directory
#------------------------------------------
setwd("~/NorthwesternU_MSPA/Classes/Generalized Linear Models - 411/Bonus Assignments/HELOC")
# include required packages
#---------------------------
# library(car)
# library(leaps)
#library(Hmisc)
library(glmnet)
# Read in the data
#------------------------------------------
df <- read.csv("heloc_test.csv",header=T)
############## Part 1: Data Exploration ##################
str(df)
summary(df)
sum(complete.cases(df))
#convert the text cases to numerics
# df$REASON<- as.numeric(factor(df$REASON))
# df$JOB<- as.numeric(factor(df$JOB))
# convert the N/As to be the column means
for(i in 1:ncol(df)){
df[is.na(df[,i]), i] <- mean(df[,i], na.rm = TRUE)
}
df_clean <- subset(df, select = -c(INDEX) )
df$P_TARGET_FLAG <-  -2.2436    +
-0.0067  	* df_clean$YOJ+
0.5607 	* df_clean$DEROG+
0.7564 	* df_clean$DELINQ+
-0.0057 * df_clean$CLAGE+
0.1537 * df_clean$NINQ+
-0.0125 	* df_clean$CLNO+
0.0492  	* df_clean$DEBTINC
df$P_TARGET_FLAG <- round(df$P_TARGET_FLAG, 2)
# For the sake of good programming hygiene, start clean
#------------------------------------------------------
# Clear Workspace
rm(list=ls())
# Clear Console:
cat("\014")
# Set working directory
#------------------------------------------
setwd("~/NorthwesternU_MSPA/Classes/Generalized Linear Models - 411/Bonus Assignments/HELOC")
# include required packages
#---------------------------
library(glmnet)
# Read in the data
#------------------------------------------
df <- read.csv("heloc_test.csv",header=T)
############## Part 1: Data Exploration ##################
str(df)
summary(df)
sum(complete.cases(df))
#convert the text cases to numerics
# df$REASON<- as.numeric(factor(df$REASON))
# df$JOB<- as.numeric(factor(df$JOB))
# Clean any NAs
df[is.na(df)] <- 0
# convert the N/As to be the column means
for(i in 1:ncol(df)){
df[is.na(df[,i]), i] <- mean(df[,i], na.rm = TRUE)
}
df_clean <- subset(df, select = -c(INDEX, TARGET_FLAG) )
df$predict <- -2.2436 -0.0067 * df_clean$YOJ + 0.5607 * df_clean$DEROG +
0.7564 * df_clean$DELINQ -0.0057 * df_clean$CLAGE + 0.1537 * df_clean$NINQ +
-0.0125 * df_clean$CLNO + 0.0492 * df_clean$DEBTINC
df$tmp = exp(df$predict)
df$tmp = df$tmp / (1.0+df$tmp)
df$P_TARGET_FLAG = round(df$tmp, 2)
prediction <- df[c("INDEX","P_TARGET_FLAG")]
write.csv(prediction, "tam_williams_heloc_scoredv2.csv", row.names = FALSE)
######## Predict 411, HELOC Extra Credit
######## Submitted by: Tamara Williams
# For the sake of good programming hygiene, start clean
#------------------------------------------------------
# Clear Workspace
rm(list=ls())
# Clear Console:
cat("\014")
# Set working directory
#------------------------------------------
setwd("~/NorthwesternU_MSPA/Classes/Generalized Linear Models - 411/Bonus Assignments/HELOC")
# include required packages
#---------------------------
library(glmnet)
# Read in the data
#------------------------------------------
df <- read.csv("heloc_test.csv",header=T)
############## Part 1: Data Exploration ##################
str(df)
summary(df)
sum(complete.cases(df))
#convert the text cases to numerics
# df$REASON<- as.numeric(factor(df$REASON))
# df$JOB<- as.numeric(factor(df$JOB))
# Clean any NAs
df[is.na(df)] <- 0
# convert the N/As to be the column means
for(i in 1:ncol(df)){
df[is.na(df[,i]), i] <- mean(df[,i], na.rm = TRUE)
}
df_clean <- subset(df, select = -c(INDEX, TARGET_FLAG) )
df$predict <- -2.2436 -0.0067 * df_clean$YOJ + 0.5607 * df_clean$DEROG +
0.7564 * df_clean$DELINQ -0.0057 * df_clean$CLAGE + 0.1537 * df_clean$NINQ +
-0.0125 * df_clean$CLNO + 0.0492 * df_clean$DEBTINC
df$tmp = exp(df$predict)
df$tmp = df$tmp / (1.0+df$tmp)
df$P_TARGET_FLAG = round(df$tmp, 2)
#subset of data set for the deliverable "Scored data file"
prediction <- df[c("INDEX","P_TARGET_FLAG")]
#####
#Note, this next function will output an Excel file in your work environment called write.xlsx.
#####
#Write prediction File
write.csv(prediction, "tam_williams_heloc_scoredv3.csv", row.names = FALSE)
