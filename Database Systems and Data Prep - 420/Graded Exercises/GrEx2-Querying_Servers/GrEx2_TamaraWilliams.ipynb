{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Do These Things With the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your csv files on your computer, do the following:\n",
    "\n",
    "1) Import each of the csv files you downloaded from the SSCC into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acctno  mail_1  mail_2  mail_3  mail_4  mail_5  mail_6  mail_7  mail_8  \\\n",
      "0  WLPAQS       0       0       0       1       0       1       1       1   \n",
      "1  WGDQLA       0       0       0       0       0       0       0       0   \n",
      "2  WDPSHS       1       0       0       0       0       0       1       0   \n",
      "3  APSYYW       1       1       1       1       1       1       1       1   \n",
      "4  SDHLPH       1       1       1       1       1       1       1       1   \n",
      "\n",
      "   mail_9  mail_10  mail_11  mail_12  mail_13  mail_14  mail_15  mail_16  \n",
      "0       1        1        1        0        1        0        1        0  \n",
      "1       0        0        0        1        1        0        0        1  \n",
      "2       0        1        0        0        1        0        1        0  \n",
      "3       1        1        1        1        1        1        1        1  \n",
      "4       1        1        1        1        1        1        1        1   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# For the data files (mail, item and customer), read the CSVs into a dataframe. Use \n",
    "# an empty string to fill in missing data.  Assumes data is in local path\n",
    "\n",
    "df_mail = pd.read_csv(\"mail.csv\", sep = \",\")\n",
    "df_mail = df_mail.fillna('')\n",
    "print df_mail.head(5),\"\\n\"\n",
    "df_item = pd.read_csv(\"items.csv\", sep = \",\")\n",
    "df_item = df_item.fillna('')\n",
    "df_cust = pd.read_csv(\"customers.csv\", sep = \",\")\n",
    "df_cust = df_cust.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Verify that there are no duplicate customer records in the _customer_ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 0 duplicate Customer records found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of duplicate customer records, and report it\n",
    "# where \"duplicate\" means all field (column) values for any 2 rows are the same\n",
    "dup_cust = df_cust.duplicated().sum()\n",
    "print \"There were\", dup_cust, \"duplicate Customer records found\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Check the item and mail data to determine whether there are any records in them for customers who are _not_ in the customer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  0  account numbers in Mail not in Customers\n",
      "There are  0  account numbers in Item not in Customers\n"
     ]
    }
   ],
   "source": [
    "# create a list of the unique customer account numbers\n",
    "cust_acc = list(df_cust['acctno'].unique())\n",
    "\n",
    "# Since we are looking for records that are in df_mail, but NOT in df_cust, use the \n",
    "#  pd.isin() function, and set to '==False' for records where the value of \n",
    "# df_mail.acctno is not in the list of unique Customer acctno's.  Repeat for df_item.  \n",
    "missing_mail = df_mail[df_mail.acctno.isin(cust_acc)==False]\n",
    "print \"There are \", len(missing_mail),\" account numbers in Mail not in Customers\"\n",
    "missing_item = df_item[df_item.acctno.isin(cust_acc)==False]\n",
    "print \"There are \", len(missing_item),\" account numbers in Item not in Customers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Create a __sqlite__ database, and write the customer, item, and mail data into it as tables.  _Do not include any item or mail data that don't match a customer_.  You may want to use the sqlalchemy Python package to do this, or the sqlite3 Python package.  Save your sqlite database for use in the future. (You may be asked to share it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Verifying Tables ********\n",
      "Length and random row match, mail table            is good\n",
      "Length and random row match, item table            is good\n",
      "Length and random row match, customers table            is good\n"
     ]
    }
   ],
   "source": [
    "# filter the dataframes to remove items that are in mail or item and not in customer, \n",
    "# save cleaned dataframe to a new name for clarity, and for importing into the DB\n",
    "clean_mail = df_mail[df_mail.acctno.isin(missing_mail['acctno'])==False]\n",
    "clean_item = df_item[df_item.acctno.isin(missing_item['acctno'])==False]\n",
    "\n",
    "# Check for database, and if it exists, delete it so can be recreated clean\n",
    "import os\n",
    "import errno\n",
    "try:\n",
    "    os.remove('XYZ_DB.db')\n",
    "except OSError as e:\n",
    "    if (e == 2):\n",
    "        pass\n",
    "\n",
    "# Create the SQLite3 database by instantiating a connection and importing the \"clean\"\n",
    "# dataframes. Commit and close to \"flush\" to disk\n",
    "import sqlite3\n",
    "db_conn = sqlite3.connect('XYZ_DB.db')\n",
    "clean_mail.to_sql(\"mail\", db_conn, if_exists='replace')\n",
    "clean_item.to_sql(\"item\", db_conn, if_exists=\"replace\")\n",
    "df_cust.to_sql(\"customers\", db_conn, if_exists='replace')\n",
    "db_conn.commit()\n",
    "db_conn.close()\n",
    "\n",
    "# verify 1) there are data in the tables,  2) the dataframe length matches the number \n",
    "# of rows in the table and 3) that a random row is the same between the dataframe and \n",
    "# table adjusting for index differences. \n",
    "# This should work since order is preserved on import\n",
    "db_conn = sqlite3.connect('XYZ_DB.db')\n",
    "c = db_conn.cursor()\n",
    "\n",
    "def check_table(df, str_table):\n",
    "    import random\n",
    "    tmp_var = '--tempVar--'\n",
    "    r_count = 0\n",
    "    q1 = 'select * from tmp_var'.replace('tmp_var', str_table)\n",
    "    for row in c.execute (q1):\n",
    "        r_count +=1\n",
    "    i = random.randint(1, len(df))\n",
    "    q2 = 'select rowid, * from tmp_var where rowid = ?'.replace('tmp_var', str_table)\n",
    "    q_cursor = c.execute(q2, [i])\n",
    "    s_res = q_cursor.fetchone()\n",
    "    d_res = df.ix[i-1]\n",
    "    if (s_res[2] == d_res.acctno) and (r_count == len(df)):\n",
    "        res_str = \"Length and random row match, tmp_var table\\\n",
    "            is good\".replace('tmp_var', str_table)\n",
    "        print res_str\n",
    "    else:\n",
    "        res_str = \"\"\"Length and random row match, tmp_var table don't match, \n",
    "            there was an error\"\"\". replace('tmp_var', str_table)\n",
    "        print res_str\n",
    "    \n",
    "print \"******* Verifying Tables ********\"\n",
    "check_table(clean_mail, 'mail')\n",
    "check_table(clean_item, 'item')\n",
    "check_table(df_cust,'customers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Create and export a csv file for XYZ to target in a direct mail marketing campaign.  This file should have the following data fields in it, and it should have a header record giving field names.  It should only include customers who have been mailed at least seven(7) times in XYZ's 16 mail campaigns.\n",
    "\n",
    "The first four \"Z\" variables above are from Experian.  They have categorical value codes that you'll find defined in the XYZ Company data documentation on Canvas \"Resources.\" For each of these \"Z\" variables, create a version that is numeric and is coded \"1\" (numeric) if the original is coded \"Y,\" and \"0\" (numeric) for any other original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Visually inspect coding results ****\n",
      "Correct: 'Y' -> 1, blank or null -> None, all else -> 0\n",
      "\n",
      "(u'WLPAQS', 9, 0, 0, u'U', u'U', u'Y', u'Y', 0, 0, 1, 1)\n",
      "(u'APSYYW', 16, 1, 129, u'U', u'U', u'Y', u'Y', 0, 0, 1, 1)\n",
      "(u'SDHLPH', 16, 1, 477, u'Y', u'U', u'Y', u'Y', 1, 0, 1, 1)\n",
      "(u'DLWWDP', 12, 3, 1806, u'U', u'U', u'Y', u'Y', 0, 0, 1, 1)\n",
      "(u'DGDSAD', 16, 7, 2229, u'U', u'U', u'Y', u'Y', 0, 0, 1, 1)\n",
      "(u'WWLYGYA', 15, 0, 0, u'U', u'U', u'Y', u'Y', 0, 0, 1, 1)\n",
      "(u'WWLYGYA', 15, 0, 0, u'U', u'U', u'Y', u'Y', 0, 0, 1, 1)\n",
      "(u'WWGGQHS', 16, 10, 9285, u'U', u'U', u'Y', u'Y', 0, 0, 1, 1)\n",
      "(u'WAWYWSQ', 8, 0, 0, u'U', u'U', u'Y', u'Y', 0, 0, 1, 1)\n",
      "(u'WLGLADQ', 14, 0, 0, u'Y', u'Y', u'Y', u'Y', 1, 1, 1, 1)\n",
      "(u'AQAPAHW', 14, 2, 186, u'', u'', u'', u'', None, None, None, None)\n",
      "(u'AQSLWWW', 15, 1, 144, u'U', u'U', u'Y', u'Y', 0, 0, 1, 1)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a new table called \"mailed\" with the customers who have been \n",
    "# mailed 7 or more times\n",
    "c.execute(\"\"\"\n",
    "    create table if not exists mailed as \n",
    "    select acctno, \n",
    "    (mail_1+mail_2+mail_3+mail_4+mail_5+mail_6+mail_7+mail_8+mail_9+\n",
    "    mail_10+mail_11+mail_12+mail_13+mail_14+mail_15+mail_16) as total_mailed \n",
    "    from mail\n",
    "    where total_mailed >= 7;\"\"\")\n",
    "\n",
    "# create the table for people to mail new campaign to; call new table \"target\". \n",
    "# Table \"target\" matches acctno from the \"customer\" and \"mailed\" tables to form \n",
    "# a new collection columns of interest for the campaign\n",
    "c.execute(\"\"\"\n",
    "    create table if not exists target as \n",
    "    select mailed.acctno, total_mailed, YTD_TRANSACTIONS_2009, YTD_SALES_2009,\n",
    "      ZHOMEENT, ZMOBAV, ZCREDIT, ZHITECH \n",
    "    from mailed, customers\n",
    "    where mailed.acctno = customers.acctno;\"\"\")\n",
    "\n",
    "# add the new columns for coding into, then perform the coding.  \n",
    "# My understanding of the task is that an empty field gets no code in the new columns.\n",
    "c.execute(\"\"\"alter table target add column ZHOMEENT01 int;\"\"\") \n",
    "c.execute(\"\"\"alter table target add column ZMOBAV01 int;\"\"\")\n",
    "c.execute(\"\"\"alter table target add column ZCREDIT01 int;\"\"\")\n",
    "c.execute(\"\"\"alter table target add column ZHITECH01 int;\"\"\")\n",
    "c.execute(\"\"\"update target set ZHOMEENT01 = (case when ZHOMEENT = \"Y\" then 1 when \n",
    "    (ZHOMEENT <> \"Y\" and (ZHOMEENT <> \"\" or ZHOMEENT <> null)) then 0 end);\"\"\")\n",
    "c.execute(\"\"\"update target set ZMOBAV01 = (case when ZMOBAV = \"Y\" then 1 when \n",
    "    (ZMOBAV <> \"Y\" and (ZMOBAV <> \"\" or ZMOBAV <> null)) then 0 end);\"\"\")\n",
    "c.execute(\"\"\"update target set ZCREDIT01 = (case when ZCREDIT = \"Y\" then 1 when \n",
    "    (ZCREDIT <> \"Y\" and (ZCREDIT <> \"\" or ZCREDIT <> null)) then 0 end);\"\"\")\n",
    "c.execute(\"\"\"update target set ZHITECH01 = (case when ZHITECH = \"Y\" then 1 when \n",
    "    (ZHITECH <> \"Y\" and (ZHITECH <> \"\" or ZHITECH <> null)) then 0 end);\"\"\")\n",
    "\n",
    "#visually inspect for correctness; \n",
    "# 6 page limit precludes getting fancy with verification\n",
    "print \"****** Visually inspect coding results ****\"\n",
    "print \"Correct: 'Y' -> 1, blank or null -> None, all else -> 0\\n\"\n",
    "for row in c.execute(\"select * from target limit 12\"):\n",
    "    print row\n",
    "print '\\n'\n",
    "\n",
    "#write the target table as a CSV file\n",
    "write_table = pd.read_sql_query('select * from target',db_conn)\n",
    "write_table.to_csv('target.csv', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Using the data that you created for exporting to the csv file, create a cross-tabulation table for each of the Z variables and the numeric versions of them that you created, showing for each that that your recoding worked as required.  Understand that the kind of cross-tabulation required has one variable's values in the rows, and the other variable's values in the columns.  Be sure to consider missing values. The total number of cases shown in your crosstabs should equal the number of customers in the csv file. Be careful to take any missing values into account in your table.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZHOMEENT01   0.0   1.0   All\n",
      "zhomeent                    \n",
      "U           6384     0  6384\n",
      "Y              0  1448  1448\n",
      "All         6384  1448  7832 \n",
      "\n",
      "ZMOBAV01   0.0  1.0   All\n",
      "zmobav                   \n",
      "U         7593    0  7593\n",
      "Y            0  239   239\n",
      "All       7593  239  7832 \n",
      "\n",
      "ZCREDIT01  0.0   1.0   All\n",
      "zcredit                   \n",
      "U          270     0   270\n",
      "Y            0  7562  7562\n",
      "All        270  7562  7832 \n",
      "\n",
      "ZHITECH01  0.0   1.0   All\n",
      "zhitech                   \n",
      "U          519     0   519\n",
      "Y            0  7313  7313\n",
      "All        519  7313  7832 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# do the cross-tabs for each \"Z_Something\"-pair, print as we go\n",
    "print pd.crosstab(write_table.zhomeent, write_table.ZHOMEENT01,margins = True), '\\n'\n",
    "print pd.crosstab(write_table.zmobav, write_table.ZMOBAV01,margins = True), '\\n'\n",
    "print pd.crosstab(write_table.zcredit, write_table.ZCREDIT01,margins = True), '\\n'\n",
    "print pd.crosstab(write_table.zhitech, write_table.ZHITECH01,margins = True), '\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "7) Pickle or Shelve your pandas DataFrames. Save your sqlite DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Commit the changes to the DB and close the connection to save to local folder\n",
    "db_conn.commit()\n",
    "db_conn.close()\n",
    "\n",
    "# pickle mail, item and customer dataframes, stored in local working directory\n",
    "clean_mail.to_pickle('XYZ_mail.pkl')\n",
    "clean_item.to_pickle('XYZ_item.pkl')\n",
    "df_cust.to_pickle('XYZ_cust.pkl')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
